{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_util import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "class Brick:\n",
    "    x_center = 0\n",
    "    y_center = 0\n",
    "    pixel_width = 0\n",
    "    pixel_height = 0\n",
    "    rotation_degrees = 0.0\n",
    "    \n",
    "'''\n",
    "https://github.com/alexleavitt/uscplayspokemon/blob/master/tommycam.py\n",
    "'''\n",
    "def get_video_capture_frame(video_capture_url_jpg_str):\n",
    "    img_request = imageio.imread(video_capture_url_jpg_str)[:,:,::-1] #JPG to BGR\n",
    "    if (img_request is None) or (not img_request.shape):\n",
    "        print('No image')\n",
    "        return False, None\n",
    "    return True, img_request\n",
    "\n",
    "'''\n",
    "https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html\n",
    "'''\n",
    "def threshold_frame(img_frame, min_threshold):\n",
    "    ret, thresholded_frame = cv2.threshold(img_frame, min_threshold, 255, cv2.THRESH_BINARY)\n",
    "    return thresholded_frame\n",
    "\n",
    "\n",
    "'''\n",
    "https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html\n",
    "https://docs.opencv.org/master/d4/d86/group__imgproc__filter.html#ga9d7064d478c95d60003cf839430737ed\n",
    "'''\n",
    "def remove_noise(img_frame):\n",
    "    result = img_frame\n",
    "    result = cv2.bilateralFilter(result,16,32,32) \n",
    "    \n",
    "    kernel = np.ones((2, 2),np.uint8)\n",
    "    result = cv2.morphologyEx(result, cv2.MORPH_OPEN, kernel) \n",
    "    \n",
    "    kernel = np.ones((9, 9),np.uint8)\n",
    "    result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel)\n",
    "   \n",
    "    result = cv2.bilateralFilter(result,3,16,16)\n",
    "    return result\n",
    "\n",
    "'''\n",
    "https://docs.opencv.org/master/df/d9d/tutorial_py_colorspaces.html\n",
    "https://stackoverflow.com/questions/56905592/automatic-contrast-and-brightness-adjustment-of-a-color-photo-of-a-sheet-of-pape????\n",
    "'''\n",
    "def blue_color_mask(img_frame):\n",
    "    result = img_frame\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)\n",
    "    lower_blue = np.array([50,50,80])\n",
    "    upper_blue = np.array([140,255,255])\n",
    "    result = cv2.inRange(result, lower_blue, upper_blue)\n",
    "\n",
    "    ret, result = cv2.threshold(result, 50, 255, cv2.THRESH_BINARY)\n",
    "    return result\n",
    "\n",
    "def red_color_mask(img_frame):\n",
    "    result = img_frame\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([145,145,0])\n",
    "    upper_red = np.array([255,255,255])\n",
    "    result = cv2.inRange(result, lower_red, upper_red)\n",
    "\n",
    "    ret, result = cv2.threshold(result, 50, 255, cv2.THRESH_BINARY)\n",
    "    return result\n",
    "\n",
    "def filter_blue_bricks(img_frame):\n",
    "    frame = img_frame\n",
    "    frame = blue_color_mask(frame)\n",
    "    frame = remove_noise(frame)\n",
    "    blue_brick_arr = find_bricks(frame) \n",
    "    return blue_brick_arr\n",
    "\n",
    "def filter_red_bricks(img_frame):\n",
    "    frame = img_frame\n",
    "    frame = red_color_mask(frame)\n",
    "    frame = remove_noise(frame)\n",
    "    red_brick_arr = find_bricks(frame) \n",
    "    return red_brick_arr\n",
    "\n",
    "def init_get_ref_pixel_width(img_frame):\n",
    "    bricks = filter_blue_bricks(img_frame)\n",
    "    if len(bricks) is 1:\n",
    "        calibration_brick_pixel_width = bricks[0].pixel_width\n",
    "        return calibration_brick_pixel_width\n",
    "    return 0\n",
    "\n",
    "def find_bricks(img_frame):\n",
    "    frame = img_frame\n",
    "    contours, hierarchy = cv2.findContours(frame.astype('uint8'), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    brick_arr = []\n",
    "    for contour in contours:\n",
    "        pixel_areal = cv2.contourArea(contour)\n",
    "        if(pixel_areal > 600):\n",
    "            brick = Brick()\n",
    "            M = cv2.moments(contour)\n",
    "            brick.x_center = int(M['m10']/M['m00'])\n",
    "            brick.y_center = int(M['m01']/M['m00'])\n",
    "            rectangle_w_rotation = cv2.minAreaRect(contour)\n",
    "            brick.pixel_width = rectangle_w_rotation[1][0]\n",
    "            brick.pixel_height = rectangle_w_rotation[1][1]\n",
    "            brick.rotation_degrees = rectangle_w_rotation[2]\n",
    "            brick_arr.append(brick)\n",
    "    return brick_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step was the get the video capture frame. When doing this the image has to be using BGR colors due to the OpenCV framework using BGR as a standard. After this the image is cropped to center the Crustcrawler on the x-axis. Any part of the image that is also outside of clear surface of the table is also removed. The metallic edges of the table reflect a lot of light, especially blue. Presumeably due to the environment light of the room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onTimer(self, event):\n",
    "        ret, frame = vision.get_video_capture_frame('http://192.168.1.100/image.jpg')\n",
    "        if ret:\n",
    "            cropped_frame = frame[75:frame.shape[0]-140, 35:frame.shape[1]-5]\n",
    "            blue_contours = vision.filter_blue_bricks(cropped_frame)\n",
    "            red_contours = vision.filter_red_bricks(cropped_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_capture_frame(video_capture_url_jpg_str):\n",
    "    img_request = imageio.imread(video_capture_url_jpg_str)[:,:,::-1] #JPG to BGR\n",
    "    if (img_request is None) or (not img_request.shape):\n",
    "        print('No image')\n",
    "        return False, None\n",
    "    return True, img_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, img_0deg = get_video_capture_frame('cr2.jpg')\n",
    "ret, img_45deg = get_video_capture_frame('cr4.jpg')\n",
    "ret, img_calibrate = get_video_capture_frame('cr_cal.jpg')\n",
    "\n",
    "\n",
    "plt.imshow(img_0deg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
